{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_04_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNKXrJ8Fe29aVtjrEn6stUp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VitalyGladyshev/gb_pytorch/blob/main/HW_04_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fJ_QYJ6-EnK"
      },
      "source": [
        "#ДЗ 4 Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i63dy6pn-JzA"
      },
      "source": [
        "## Задание 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUZPcTfDLpsD"
      },
      "source": [
        "Необходимо доработать обучение нейросети, что мы разбирали на уроке.(Посмотрите чего не хватает в процессе обучения и подготовки данных)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elUZPPUJ9co8",
        "outputId": "bb30b02d-2919-4bcb-eee1-96abae99cc54"
      },
      "source": [
        "pip install segmentation_models_pytorch"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting segmentation_models_pytorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/54/8953f9f7ee9d451b0f3be8d635aa3a654579abf898d17502a090efe1155a/segmentation_models_pytorch-0.1.3-py3-none-any.whl (66kB)\n",
            "\r\u001b[K     |█████                           | 10kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 30kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 40kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 51kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 61kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.8MB/s \n",
            "\u001b[?25hCollecting pretrainedmodels==0.7.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from segmentation_models_pytorch) (0.8.1+cu101)\n",
            "Collecting timm==0.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/2d/39ecc56fbb202e1891c317e8e44667299bc3b0762ea2ed6aaaa2c2f6613c/timm-0.3.2-py3-none-any.whl (244kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 8.5MB/s \n",
            "\u001b[?25hCollecting efficientnet-pytorch==0.6.3\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.7.0+cu101)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.41.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.15.0)\n",
            "Building wheels for collected packages: pretrainedmodels, efficientnet-pytorch\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp36-none-any.whl size=60963 sha256=ffc130ad1b3f2bfe131cce483faf63076c3b66a7a956ceb2ac5db40a967239ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-cp36-none-any.whl size=12420 sha256=53e91662f85ad76b7c4565edbe0c87930ee242b6f2b2f9d23782f5e5ccce1a8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/1e/a9/2a578ba9ad04e776e80bf0f70d8a7f4c29ec0718b92d8f6ccd\n",
            "Successfully built pretrainedmodels efficientnet-pytorch\n",
            "Installing collected packages: munch, pretrainedmodels, timm, efficientnet-pytorch, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.6.3 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.1.3 timm-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bonov13NCly"
      },
      "source": [
        "import segmentation_models_pytorch as smp"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9JbwZbBNCo9"
      },
      "source": [
        "!pip install -U -q kaggle\r\n",
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "v1m5nL9oWx3D",
        "outputId": "6488ea15-a427-4897-ba64-6fcb39f6805c"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.upload()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3ff47cb3-1347-4f25-8a77-174a41ae4147\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3ff47cb3-1347-4f25-8a77-174a41ae4147\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"vitalygladyshev\",\"key\":\"3353367a1e22b48542ed3c3946bdf3e4\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCJ6ERzEWx59",
        "outputId": "253cd1ed-42ad-439b-f45b-a09df7329a66"
      },
      "source": [
        "!mv kaggle.json ~/.kaggle/\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json\r\n",
        "!ls -la ~/.kaggle/"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 16\n",
            "drwxr-xr-x 2 root root 4096 Dec 15 20:06 .\n",
            "drwx------ 1 root root 4096 Dec 15 17:43 ..\n",
            "-rw------- 1 root root   71 Dec 15 20:05 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXMrctSGWyAW",
        "outputId": "9f9ee797-662f-416e-b7ba-83456b7e734f"
      },
      "source": [
        "!kaggle datasets list -s lyft-udacity-challenge"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "ref                                                       title                                               size  lastUpdated          downloadCount  \n",
            "--------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  \n",
            "kumaresanmanickavelu/lyft-udacity-challenge               Semantic Segmentation for Self Driving Cars          5GB  2018-05-18 05:59:42           2000  \n",
            "morrisb/semantic-segmentation-with-carla-and-tpus         Semantic Segmentation With CARLA And TPUs            3GB  2020-10-18 10:11:51             16  \n",
            "austenmy/udacity-enrollments                              Udacity Enrollments                                 10KB  2018-04-06 00:54:43             91  \n",
            "pbdanny/udacity-project-submissions                       Udacity Project Submission                          24KB  2018-05-10 11:41:36             45  \n",
            "samtyagi/audacity-ab-testing                              audacity ab testing                                103KB  2019-01-29 15:00:02            114  \n",
            "souravs17031999/flowerclassifierudacitypretrainedweights  Flower-classifier-Udacity-pretrained-Weights       211MB  2020-04-19 12:22:52             24  \n",
            "austenmy/udacity-daily-engagement                         Udacity Daily Engagement                           649KB  2018-04-06 01:01:01            100  \n",
            "luizoamorim/analysis-bay-area-bike-share-udacity          Analysis Bay Area Bike Share Udacity               243KB  2017-11-10 00:16:53            108  \n",
            "fabiocorreacordeiro/udacity-titanic-data                  Udacity Titanic Data                                22KB  2017-11-01 20:46:37             44  \n",
            "tammyrotem/udacity-ab-testing-finalproject-data           Udacity_AB_Testing_FinalProject_Data                679B  2018-01-03 14:55:38             60  \n",
            "schirmerchad/bostonhoustingmlnd                           Boston Housing                                       4KB  2017-06-11 15:07:11           8789  \n",
            "madushan1996/udacity                                      Udacity                                            420MB  2020-08-23 15:21:22              0  \n",
            "abhinavmanoj/udacity-simulator-dataset                    Udacity Simulator Dataset                           32MB  2020-06-09 18:30:13              7  \n",
            "jpdaza/udacity-intro-to-data-analysis                     Udacity Intro to Data Analysis                       9MB  2018-06-10 18:10:56             70  \n",
            "tusharcode/selfdriving-car-udacity                        Self-Driving Car Udacity                           243MB  2020-04-23 03:44:26             23  \n",
            "evertonsa/udacitybrazilmedicalappointments                UdacityBrazilMedicalAppointments                     2MB  2017-10-29 15:55:19             18  \n",
            "zaynena/selfdriving-car-simulator                         Self-Driving Car Simulator                           2GB  2019-04-06 23:38:58            512  \n",
            "priya2908/chopsticks-1992                                 Beginner Projects - Ergonomic Study on Chopsticks    1KB  2017-06-11 19:44:20            371  \n",
            "swimmingwhale/udacitymachinelearningdatasets              Udacity-Machine-Learning-Datasets                    4MB  2018-09-08 01:45:03              2  \n",
            "davydev/udacity-intro-to-ml                               udacity-intro-to-machine-learning                    4MB  2020-07-26 08:42:09              0  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HplVxzolWx9U",
        "outputId": "af622c39-1064-4236-c85e-cabe322a235a"
      },
      "source": [
        "!kaggle datasets download -d kumaresanmanickavelu/lyft-udacity-challenge\r\n",
        "!ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading lyft-udacity-challenge.zip to /content\n",
            "100% 5.11G/5.11G [01:46<00:00, 32.2MB/s]\n",
            "100% 5.11G/5.11G [01:46<00:00, 51.6MB/s]\n",
            "lyft-udacity-challenge.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96oaWxn-Z7DE"
      },
      "source": [
        "from zipfile import ZipFile"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq_Y3X0DaCqZ"
      },
      "source": [
        "zip_file = ZipFile('lyft-udacity-challenge.zip')\r\n",
        "zip_file.extractall(\"./lyft-udacity-challenge\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHnzwQBIaCyq",
        "outputId": "f221ec2b-5e69-4a94-a77c-92c8908c3980"
      },
      "source": [
        "!path = \"lyft-udacity-challenge\"\r\n",
        "!ls -ls $path"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: path: command not found\n",
            "total 5357052\n",
            "      4 drwxr-xr-x 12 root root       4096 Dec 15 17:42 lyft-udacity-challenge\n",
            "5357044 -rw-r--r--  1 root root 5485605432 Dec 15 17:39 lyft-udacity-challenge.zip\n",
            "      4 drwxr-xr-x  1 root root       4096 Dec  2 22:04 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEyCR3kiWyDl"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiIr9JOpd14M"
      },
      "source": [
        "labels = ['Unlabeled','Building','Fence','Other',\r\n",
        "          'Pedestrian', 'Pole', 'Roadline', 'Road',\r\n",
        "          'Sidewalk', 'Vegetation', 'Car','Wall',\r\n",
        "          'Traffic sign']"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1x7H1h1edCr"
      },
      "source": [
        "path = \"lyft-udacity-challenge\""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCBsoCsed18L"
      },
      "source": [
        "cameraRGB = []\r\n",
        "cameraSeg = []\r\n",
        "for root, dirs, files in os.walk(path):\r\n",
        "    for name in files:\r\n",
        "        f = os.path.join(root, name)\r\n",
        "        if 'CameraRGB' in f:\r\n",
        "            cameraRGB.append(f)\r\n",
        "        elif 'CameraSeg' in f:\r\n",
        "            cameraSeg.append(f)\r\n",
        "        else:\r\n",
        "            break"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk3ZwXvDd2AU",
        "outputId": "ded65709-2367-43db-f96b-3faee5c63ccc"
      },
      "source": [
        "cameraRGB[-1], cameraSeg[-1]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('lyft-udacity-challenge/dataC/dataC/CameraRGB/F64-44.png',\n",
              " 'lyft-udacity-challenge/dataC/dataC/CameraSeg/F64-44.png')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU1-185NkF81",
        "outputId": "ddf08916-a58f-4308-b244-c6d1c64d59c4"
      },
      "source": [
        "df = pd.DataFrame({'cameraRGB': cameraRGB, 'cameraSeg': cameraSeg})\r\n",
        "# Отсортируем  датафрейм по значениям\r\n",
        "df.sort_values(by='cameraRGB',inplace=True)\r\n",
        "# Используем функцию,\r\n",
        "# лагодаря которой индексация значений \r\n",
        "# будет начинаться с 0.\r\n",
        "df.reset_index(drop=True, inplace=True)\r\n",
        "# Выведем первые ять значений нашего датафрейма\r\n",
        "print(df.head(5))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                           cameraRGB                                          cameraSeg\n",
            "0  lyft-udacity-challenge/dataA/dataA/CameraRGB/0...  lyft-udacity-challenge/dataA/dataA/CameraSeg/0...\n",
            "1  lyft-udacity-challenge/dataA/dataA/CameraRGB/0...  lyft-udacity-challenge/dataA/dataA/CameraSeg/0...\n",
            "2  lyft-udacity-challenge/dataA/dataA/CameraRGB/0...  lyft-udacity-challenge/dataA/dataA/CameraSeg/0...\n",
            "3  lyft-udacity-challenge/dataA/dataA/CameraRGB/0...  lyft-udacity-challenge/dataA/dataA/CameraSeg/0...\n",
            "4  lyft-udacity-challenge/dataA/dataA/CameraRGB/0...  lyft-udacity-challenge/dataA/dataA/CameraSeg/0...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G6-6RCtkGGC",
        "outputId": "1d6cfb81-4a1c-4afc-dcbf-8d3b993cbeb8"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   cameraRGB  10000 non-null  object\n",
            " 1   cameraSeg  10000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 156.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-tm-DhHd2D9"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from PIL import Image\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.nn import functional as F\r\n",
        "import time"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "molwhPU5kGQE"
      },
      "source": [
        "class CustomDatasetFromImages(Dataset):\r\n",
        "    def __init__(self, data_info):\r\n",
        "        # Подаем наш подготовленный датафрейм\r\n",
        "        self.data_info = data_info\r\n",
        "        \r\n",
        "        # Разделяем датафрейм на rgb картинки \r\n",
        "        self.image_arr = self.data_info.iloc[:,0]\r\n",
        "        # и на сегментированные картинки\r\n",
        "        self.label_arr = self.data_info.iloc[:,1]\r\n",
        "        \r\n",
        "        # Количество пар картинка-сегментация\r\n",
        "        self.data_len = len(self.data_info.index)\r\n",
        "    def __getitem__(self, index):\r\n",
        "        # Читаем картинку и сразу же представляем ее в виде numpy-массива \r\n",
        "        # размера 600х800 float-значний\r\n",
        "        img = np.asarray(Image.open(self.image_arr[index])).astype('float')\r\n",
        "        # Нормализуем изображение в значениях [0,1]\r\n",
        "        img = torch.as_tensor(img)/255    \r\n",
        "        # 1) unsqueeze - меняет размерность img c (600, 800, 3) -> (1, 600, 800, 3),\r\n",
        "        # т.е. оборачивает картинку в батч размером в одну картинку\r\n",
        "        # 2) permute - меняет местами измерения , т.е. (1, 600, 800, 3) -> (1, 3, 600, 800)\r\n",
        "        img = img.unsqueeze(0).permute(0,3,1,2)\r\n",
        "        # Мы используем функцию интерполяции для того,\r\n",
        "        # чтобы поменять рамерность картинки с 800х600 на 256х256\r\n",
        "        img = F.interpolate(input=img, size=256, align_corners=False, mode='bicubic')\r\n",
        "        \r\n",
        "        # итаем сегментированную картинку и сразу же представляем ее в виде numpy-массива \r\n",
        "        # размера 600х800 float-значний\r\n",
        "        lab = np.asarray(plt.imread(self.label_arr[index]))[:,:,0]*255\r\n",
        "        \r\n",
        "        # Упаковываем ее в pytorch-тензор и оборачиваем ее в батч из одной каринки,\r\n",
        "        # но при этом заполняем 13 каналов масками нужных классов\r\n",
        "        # Т.е. там, где например класс автомобилей (10 по счету канал) - все пиксели 0 \r\n",
        "        # если не принадлежат классу, и 1 если принадлежат \r\n",
        "        x_out = torch.as_tensor(np.where(lab == 0, 255, 0)).unsqueeze(0)\r\n",
        "        for i in range(1, 13):\r\n",
        "            mask = np.asarray(plt.imread(self.label_arr[index]))[:,:,0]*255\r\n",
        "            mask = np.where(mask == i, 255, 0)\r\n",
        "            x = torch.as_tensor(mask).unsqueeze(0)\r\n",
        "            x_out =  torch.cat((x_out,x),dim=0)    \r\n",
        "        x_out = x_out.float()\r\n",
        "        \r\n",
        "        lab = x_out.unsqueeze(0)\r\n",
        "        # делаем ресайз картинки на 256х256\r\n",
        "        lab = F.interpolate(input=lab, size=256, mode='nearest')\r\n",
        "        \r\n",
        "        return (img.float(), lab.float())\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return self.data_len"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv78_E2PlQOs"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "# 80 % в тренировочную выборку, 20 - в тестовую\r\n",
        "X_data, X_test = train_test_split(df, test_size=0.2)\r\n",
        "# 20 - в валидационную\r\n",
        "X_train, X_valid = train_test_split(X_data, test_size=0.2)\r\n",
        "\r\n",
        "# Упорядочиваем индексацию\r\n",
        "X_train.reset_index(drop=True,inplace=True)\r\n",
        "X_valid.reset_index(drop=True,inplace=True)\r\n",
        "X_test.reset_index(drop=True,inplace=True)\r\n",
        "\r\n",
        "# Оборачиваем каждую выборку в наш кастомный датасет\r\n",
        "train_data = CustomDatasetFromImages(X_train[:300])\r\n",
        "valid_data = CustomDatasetFromImages(X_valid[:300])\r\n",
        "test_data = CustomDatasetFromImages(X_test)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Eln4fgtmirG"
      },
      "source": [
        "batch_s = 10\r\n",
        "\r\n",
        "train_data_loader = DataLoader(train_data, batch_size=batch_s, shuffle=True)\r\n",
        "valid_data_loader = DataLoader(valid_data, batch_size=batch_s, shuffle=True)\r\n",
        "test_data_loader = DataLoader(test_data, batch_size=1, shuffle=False)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7ittFGJd2IL",
        "outputId": "87808a80-879d-4aa5-b0a7-11f5a0114b94"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "print(device)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lggxKFWjoLuH"
      },
      "source": [
        "class SoftDiceLoss(nn.Module):\r\n",
        "    def __init__(self, weight=None, size_average=True):\r\n",
        "        super(SoftDiceLoss, self).__init__()\r\n",
        "\r\n",
        "    def forward(self, logits, targets):\r\n",
        "        smooth =1\r\n",
        "        num = targets.size(0)\r\n",
        "        probs = torch.sigmoid(logits)\r\n",
        "        m1 = probs.view(num, -1)\r\n",
        "        m2 = targets.view(num, -1)\r\n",
        "        intersection = (m1 * m2)\r\n",
        "\r\n",
        "        score =2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\r\n",
        "        score =1 - score.sum() / num\r\n",
        "        return score"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WbxUle-pUA7"
      },
      "source": [
        "learning_rate = 0.001\r\n",
        "epochs = 7\r\n",
        "\r\n",
        "# создание модели\r\n",
        "segmodel = smp.Unet('resnet34', classes=13, activation='softmax').to(device)\r\n",
        "\r\n",
        "criterion = SoftDiceLoss()\r\n",
        "optimizer = torch.optim.Adam(segmodel.parameters(), lr=learning_rate)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy5vRkk3aHVu"
      },
      "source": [
        "path_checkpoint = \"checkpoints\"\r\n",
        "if not os.path.exists(path_checkpoint):\r\n",
        "    os.mkdir(path_checkpoint)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TpAPX0vgtji",
        "outputId": "fa4796a0-c2bb-4ccc-f8e2-70cc18a5a79c"
      },
      "source": [
        "ls -la"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 5357068\n",
            "drwxr-xr-x  1 root root       4096 Dec 15 17:46 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x  1 root root       4096 Dec 15 18:56 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x  2 root root       4096 Dec 15 19:23 \u001b[01;34mcheckpoints\u001b[0m/\n",
            "drwxr-xr-x  1 root root       4096 Dec 10 17:17 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 12 root root       4096 Dec 15 17:42 \u001b[01;34mlyft-udacity-challenge\u001b[0m/\n",
            "-rw-r--r--  1 root root 5485605432 Dec 15 17:39 lyft-udacity-challenge.zip\n",
            "drwxr-xr-x  1 root root       4096 Dec  2 22:04 \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HSeQtHQMxjr",
        "outputId": "ab2908fe-93b4-4608-e691-9c079a7a51cb"
      },
      "source": [
        "epoch_losses = []\r\n",
        "epoch_val_losses = []\r\n",
        "\r\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\r\n",
        "    running_loss = 0.0\r\n",
        "    cum_loss = []\r\n",
        "\r\n",
        "    print(f'Epoch: {epoch+1}')\r\n",
        "    time1 = time.time()\r\n",
        "    segmodel.train()\r\n",
        "    for i, data in enumerate(train_data_loader, 0):\r\n",
        "        # get the inputs; data is a list of [inputs, labels]\r\n",
        "        inputs, labels = data\r\n",
        "        inputs = inputs.to(device) # .cuda()\r\n",
        "        labels = labels.to(device) # .cuda()\r\n",
        "\r\n",
        "        # zero the parameter gradients\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        # forward + backward + optimize\r\n",
        "        outputs = segmodel(inputs[0])\r\n",
        "        loss = criterion(outputs, labels[0,0,:,:,:])\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        # print statistics\r\n",
        "        running_loss += loss.item()\r\n",
        "        cum_loss.append(loss.item())\r\n",
        "        if not (i+1) % 10:    # print every 10 mini-batches\r\n",
        "            print(f'\\tbatchcount: {i+1}, avg. loss for last {batch_s*10} images: {running_loss/(batch_s*10):.5f}')\r\n",
        "            running_loss = 0.0\r\n",
        "\r\n",
        "    time2 = time.time()\r\n",
        "    epoch_losses.append(np.mean(cum_loss))\r\n",
        "    torch.save(segmodel.state_dict(), path_checkpoint + f\"/checkpoint_ep_{epoch}.pth\")\r\n",
        "\r\n",
        "    cum_loss = []\r\n",
        "    segmodel.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "        running_val_loss = 0.0\r\n",
        "        for i, data in enumerate(valid_data_loader, 0):\r\n",
        "            inputs, labels = data\r\n",
        "            inputs = inputs.to(device) # .cuda()\r\n",
        "            labels = labels.to(device) # .cuda()\r\n",
        "\r\n",
        "            outputs = segmodel(inputs[0])\r\n",
        "            loss = criterion(outputs, labels[0,0,:,:,:])\r\n",
        "\r\n",
        "            running_val_loss += loss.item()\r\n",
        "            cum_loss.append(loss.item())\r\n",
        "\r\n",
        "    epoch_val_losses.append(np.mean(cum_loss))\r\n",
        "    print(f'\\n  Epoch {epoch+1}, loss: {epoch_losses[-1]:.5f} loss_val: {epoch_val_losses[-1]:.5f} time = {time2-time1:.2f} sec\\n')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/segmentation_models_pytorch/base/modules.py:102: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self.activation(x)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tbatchcount: 10, avg. loss for last 100 images: 0.02925\n",
            "\tbatchcount: 20, avg. loss for last 100 images: 0.02150\n",
            "\tbatchcount: 30, avg. loss for last 100 images: 0.01630\n",
            "\n",
            "  Epoch 1, loss: 0.22349 loss_val: 0.16014 time = 119.72 sec\n",
            "\n",
            "Epoch: 2\n",
            "\tbatchcount: 10, avg. loss for last 100 images: 0.01411\n",
            "\tbatchcount: 20, avg. loss for last 100 images: 0.01426\n",
            "\tbatchcount: 30, avg. loss for last 100 images: 0.00962\n",
            "\n",
            "  Epoch 2, loss: 0.12664 loss_val: 0.14178 time = 117.87 sec\n",
            "\n",
            "Epoch: 3\n",
            "\tbatchcount: 10, avg. loss for last 100 images: 0.01564\n",
            "\tbatchcount: 20, avg. loss for last 100 images: 0.01297\n",
            "\tbatchcount: 30, avg. loss for last 100 images: 0.00866\n",
            "\n",
            "  Epoch 3, loss: 0.12420 loss_val: 0.09678 time = 117.88 sec\n",
            "\n",
            "Epoch: 4\n",
            "\tbatchcount: 10, avg. loss for last 100 images: 0.00896\n",
            "\tbatchcount: 20, avg. loss for last 100 images: 0.00977\n",
            "\tbatchcount: 30, avg. loss for last 100 images: 0.01321\n",
            "\n",
            "  Epoch 4, loss: 0.10650 loss_val: 0.09771 time = 117.85 sec\n",
            "\n",
            "Epoch: 5\n",
            "\tbatchcount: 10, avg. loss for last 100 images: 0.00863\n",
            "\tbatchcount: 20, avg. loss for last 100 images: 0.00687\n",
            "\tbatchcount: 30, avg. loss for last 100 images: 0.00778\n",
            "\n",
            "  Epoch 5, loss: 0.07760 loss_val: 0.10249 time = 119.00 sec\n",
            "\n",
            "Epoch: 6\n",
            "\tbatchcount: 10, avg. loss for last 100 images: 0.00752\n",
            "\tbatchcount: 20, avg. loss for last 100 images: 0.01088\n",
            "\tbatchcount: 30, avg. loss for last 100 images: 0.01371\n",
            "\n",
            "  Epoch 6, loss: 0.10704 loss_val: 0.09325 time = 117.33 sec\n",
            "\n",
            "Epoch: 7\n",
            "\tbatchcount: 10, avg. loss for last 100 images: 0.00925\n",
            "\tbatchcount: 20, avg. loss for last 100 images: 0.01228\n",
            "\tbatchcount: 30, avg. loss for last 100 images: 0.00686\n",
            "\n",
            "  Epoch 7, loss: 0.09462 loss_val: 0.08674 time = 117.05 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjA8jZlfcpfZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "a7f34983-b412-4a25-c76a-4e7ee739cf83"
      },
      "source": [
        "plt.plot(np.arange(1, 8), epoch_losses, 'go-', label='train loss')\r\n",
        "plt.plot(np.arange(1, 8), epoch_val_losses, 'ro-', label='validation loss')\r\n",
        "\r\n",
        "plt.legend(loc=\"upper right\")\r\n",
        "plt.grid(color=\"lightgrey\")\r\n",
        "plt.title('Сравнение train и valid loss' )\r\n",
        "plt.show()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjH9bm_6_Kcj"
      },
      "source": [
        "## Задание 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3iXQuiz_Red"
      },
      "source": [
        "Необходимо скачать и подготовить датасет https://www.kaggle.com/olekslu/makeup-lips-segmentation-28k-samples/notebooks для обучения модели на губы(т.е. 2 класса: губы/не губы)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9871z7EB3J12",
        "outputId": "6502b5a7-83e5-497c-dcb9-8a3f80657dcb"
      },
      "source": [
        "!kaggle datasets list -s lipstick"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "ref                                                 title                                      size  lastUpdated          downloadCount  \n",
            "--------------------------------------------------  ----------------------------------------  -----  -------------------  -------------  \n",
            "olgabelitskaya/quick-draw-images-from-key-points-4  Quick, Draw! Images from Key Points 4     350MB  2020-07-25 06:57:20              9  \n",
            "olekslu/makeup-lips-segmentation-28k-samples        Makeup. Pixel Perfect Lips Segmentation.    2GB  2020-06-10 09:00:21            120  \n",
            "pevogam/cognitive-stimuli                           Cognitive stimuli                         254MB  2020-11-01 11:25:16              7  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4rVTrGo_7mC",
        "outputId": "0203f55e-1971-4615-daab-73f425d70571"
      },
      "source": [
        "!kaggle datasets download -d olekslu/makeup-lips-segmentation-28k-samples\r\n",
        "!ls"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading makeup-lips-segmentation-28k-samples.zip to /content\n",
            "100% 2.37G/2.38G [00:32<00:00, 34.4MB/s]\n",
            "100% 2.38G/2.38G [00:33<00:00, 77.3MB/s]\n",
            "checkpoints\t\tlyft-udacity-challenge.zip\t\t  sample_data\n",
            "lyft-udacity-challenge\tmakeup-lips-segmentation-28k-samples.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f1OWCpIBvbv"
      },
      "source": [
        "from zipfile import ZipFile\r\n",
        "\r\n",
        "zip_file = ZipFile('makeup-lips-segmentation-28k-samples.zip')\r\n",
        "zip_file.extractall(\"./lips_segmentation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eML_uEtTBv1Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzJzpfQcBv49"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsPMSy8E_Mjt"
      },
      "source": [
        "## Задание 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvmjUKUt_SVQ"
      },
      "source": [
        "Обучить Модель на выбор из segmentation_models_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ6bRlC3_Nq6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n4ifZqm_O3f"
      },
      "source": [
        "## Задание 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqdRlltq_TA_"
      },
      "source": [
        "Переделайте архитектуру декодера Unet так, как в этой работе https://www.ics.uci.edu/~haoyum3/papers/slides_icivc.pdf. Эта тема пересекается с темой о второго вебинара о LSTM-сетях. И попробуйте обучить получившуюся нейронную сеть."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgnfkGaA_QUA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}