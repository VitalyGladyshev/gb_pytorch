{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "veg7amh5kk8cfeiiswknk"
   },
   "source": [
    "# ДЗ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellId": "3isyc7267f7bkdgm7w7vud"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    }
   ],
   "source": [
    "from cloud_ml.storage.api import Storage\n",
    "\n",
    "# To retrieve client secret:\n",
    "# 1. Go to link: https://developers.google.com/drive/api/v3/quickstart/python\n",
    "# 2. Press \"Enable the drive API\"\n",
    "# 3. Choose \"TVs and limited input devices\"\n",
    "client_secret = {8:\")\"}\n",
    "\n",
    "# downloading contents of the remote file into the local one\n",
    "gdrive = Storage.gdrive(client_secret)\n",
    "gdrive_file_id = '1CUZnBtYwifVXS21yVg62T-vrPVayso5H'\n",
    "dst_path = 'data/nturgbd_skeletons_s001_to_s017.zip'\n",
    "gdrive.get(gdrive_file_id, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellId": "jvfl6qx2i8rjgunh0i4lxb"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellId": "x6uvzuh1m5m0om1gr2ml4bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:475: UserWarning: The following variables cannot be serialized: zipfile\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# fname = 'datasets.zip'\n",
    "zipfile = ZipFile(dst_path)\n",
    "zipfile.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellId": "jjgwfotc3vknftcb58n9cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    }
   ],
   "source": [
    "client_secret = {\"installed\":{\"client_id\":\"857370663792-fiev084kokkeivk2qbvq95qvc9gcs6h0.apps.googleusercontent.com\",\"project_id\":\"quickstart-1606583721372\",\"auth_uri\":\"https://accounts.google.com/o/oauth2/auth\",\"token_uri\":\"https://oauth2.googleapis.com/token\",\"auth_provider_x509_cert_url\":\"https://www.googleapis.com/oauth2/v1/certs\",\"client_secret\":\"DKtGi6FZOWvWrPhr5Irp-Wbm\",\"redirect_uris\":[\"urn:ietf:wg:oauth:2.0:oob\",\"http://localhost\"]}}\n",
    "gdrive = Storage.gdrive(client_secret)\n",
    "\n",
    "gdrive_file_ms_id = '1eCKZ_4MEGHE3IK0t-tS-AOF3D4lCXkdN'\n",
    "file_path_sampl_miss = 'NTU_RGBD_samples_with_missing_skeletons.txt'\n",
    "gdrive.get(gdrive_file_ms_id, file_path_sampl_miss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "k5ac8zote8n3dr0qi0u27g"
   },
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "zprgeqeqjhoyueyadshmpo"
   },
   "source": [
    "Собрать класс датасет с функциями из ноутбука по генерации датасета. Надо функции перенести в класс + добавить возможность при инициализации менять длину последовательности кадров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "cellId": "2pal488j0mffchi620uyzb"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellId": "pyhw249fd1bl2e4zcq5a"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "class Croped_Raw_Data:\n",
    "    def __init__(self, data_path, broken_files_path):\n",
    "        subjects = list(range(0, 28)) #количество людей выполняющих действия\n",
    "        classes = [8, 10, 22, 23, 27, 21] #классы которые будем использовать для обучения, полный список прдставлен тут https://github.com/shahroudy/NTURGB-D\n",
    "        cameras = [1, 2, 3] \n",
    "        \n",
    "        labels = []\n",
    "        counter = 0\n",
    "        files_counter = {}\n",
    "        \n",
    "        self.__files = []\n",
    "        self.__action_classes = {}\n",
    "\n",
    "        with open(broken_files_path, 'r') as f:\n",
    "            broken_files = f.read().split(\"\\n\")\n",
    "\n",
    "        raw_files = os.listdir(data_path)\n",
    "\n",
    "        for filename in raw_files:\n",
    "            if filename not in broken_files:\n",
    "                action_class = int(filename[filename.find('A') + 1:filename.find('A') + 4])\n",
    "                subject_id = int(filename[filename.find('P') + 1:filename.find('P') + 4])\n",
    "                camera_id = int(filename[filename.find('C') + 1:filename.find('C') + 4])\n",
    "                if action_class in classes and camera_id in cameras:  #and subject_id in subjects:\n",
    "                    if action_class in self.__action_classes:\n",
    "                        if files_counter[action_class] < 120:\n",
    "                            self.__files.append([filename, self.__action_classes[action_class]])\n",
    "                            files_counter[action_class] = files_counter[action_class] + 1\n",
    "                    else:\n",
    "                        self.__action_classes.update({action_class : counter})\n",
    "                        files_counter.update({action_class : 1})\n",
    "                        counter += 1\n",
    "                        self.__files.append([filename, self.__action_classes[action_class]])\n",
    "                        \n",
    "    \n",
    "    def get_files(self):\n",
    "        return self.__files\n",
    "    \n",
    "    \n",
    "    def get_classes(self):\n",
    "        return self.__action_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "cellId": "izah7qx57cqfrade1d6ap"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "data_path = \"nturgb+d_skeletons/\"\n",
    "broken_files_path = \"NTU_RGBD_samples_with_missing_skeletons.txt\"\n",
    "\n",
    "data = Croped_Raw_Data(data_path, broken_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "cellId": "wvo1ndfkvvk4pbzphlqjad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{22: 0, 23: 1, 8: 2, 27: 3, 10: 4, 21: 5}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "data.get_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "cellId": "caiiaig26trmz3l4kvxlxn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x7fb9b1954290>\n"
     ]
    }
   ],
   "source": [
    "#!L\n",
    "a, b = torch.utils.data.random_split(range(10), [3, 7], generator=torch.Generator().manual_seed(42))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "cellId": "lx0xyi3r0ynhfjlfvypn"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "class Skeleton_Dataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 inc_data, \n",
    "                 data_path, \n",
    "                 transform=None, \n",
    "                 chonk_len=45):\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.chonk_len = chonk_len\n",
    "        self.data_path = data_path\n",
    "\n",
    "        data_lst = []\n",
    "        labels_lst = []\n",
    "        numbers = {v: 0 for k, v in inc_data.get_classes().items()}\n",
    "\n",
    "        for file in inc_data.get_files():\n",
    "            frames_blocks, label = self.create_coords_blocks(file)\n",
    "            if label != [] and numbers[label[0]] <= 150:\n",
    "                numbers[label[0]] = numbers[label[0]] + len(label)\n",
    "                data_lst = data_lst + frames_blocks\n",
    "                labels_lst = labels_lst + label\n",
    "        data_np = np.asarray(data_lst)\n",
    "        labels_np = np.asarray(labels_lst)\n",
    "\n",
    "        data_sq = data_np.reshape(len(data_np), -1)\n",
    "        self.data = pd.DataFrame(data_sq)\n",
    "        self.data['labels'] = labels_np\n",
    "        self.labels = self.data.iloc[:,-1]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = np.asarray(self.data.iloc[idx,:-1]).reshape(self.chonk_len, 25*3)\n",
    "        label = self.labels.values[idx]\n",
    "        if self.transform != None:\n",
    "            item = self.transform(item)\n",
    "        return (item, label)\n",
    "    \n",
    "    \n",
    "    def read_skeleton_filter(self, file):\n",
    "        with open(file, 'r') as f:\n",
    "            skeleton_sequence = {}\n",
    "            skeleton_sequence['numFrame'] = int(f.readline())\n",
    "            skeleton_sequence['frameInfo'] = []\n",
    "            for t in range(skeleton_sequence['numFrame']):\n",
    "                frame_info = {}\n",
    "                frame_info['numBody'] = int(f.readline())\n",
    "                frame_info['bodyInfo'] = []\n",
    "\n",
    "                for m in range(frame_info['numBody']):\n",
    "                    body_info = {}\n",
    "                    body_info_key = [\n",
    "                        'bodyID', 'clipedEdges', 'handLeftConfidence',\n",
    "                        'handLeftState', 'handRightConfidence', 'handRightState',\n",
    "                        'isResticted', 'leanX', 'leanY', 'trackingState'\n",
    "                    ]\n",
    "                    body_info = {\n",
    "                        k: float(v)\n",
    "                        for k, v in zip(body_info_key, f.readline().split())\n",
    "                    }\n",
    "                    body_info['numJoint'] = int(f.readline())\n",
    "                    body_info['jointInfo'] = []\n",
    "                    for v in range(body_info['numJoint']):\n",
    "                        joint_info_key = [\n",
    "                            'x', 'y', 'z', 'depthX', 'depthY', 'colorX', 'colorY',\n",
    "                            'orientationW', 'orientationX', 'orientationY',\n",
    "                            'orientationZ', 'trackingState'\n",
    "                        ]\n",
    "                        joint_info = {\n",
    "                            k: float(v)\n",
    "                            for k, v in zip(joint_info_key, f.readline().split())\n",
    "                        }\n",
    "                        body_info['jointInfo'].append(joint_info)\n",
    "                    frame_info['bodyInfo'].append(body_info)\n",
    "                skeleton_sequence['frameInfo'].append(frame_info)\n",
    "\n",
    "        return skeleton_sequence\n",
    "\n",
    "\n",
    "    def read_xyz(self, file, max_body=1, num_joint=25):\n",
    "        seq_info = self.read_skeleton_filter(file)\n",
    "        data = np.zeros((max_body, seq_info['numFrame'], num_joint, 3))\n",
    "        for n, f in enumerate(seq_info['frameInfo']):\n",
    "            for m, b in enumerate(f['bodyInfo']):\n",
    "                for j, v in enumerate(b['jointInfo']):\n",
    "                    if m < max_body and j < num_joint:\n",
    "                        data[m, n, j, :] = [v['x'], v['y'], v['z']]\n",
    "        return data\n",
    "\n",
    "\n",
    "    def create_coords_blocks(self, test_file):   \n",
    "        frame_counter = 0\n",
    "        new_labels = []\n",
    "        new_frames = []\n",
    "        blocks = []\n",
    "\n",
    "        test_frames = self.read_xyz(self.data_path + test_file[0])[0]\n",
    "        label = test_file[1]\n",
    "        slice_len = self.chonk_len * int(len(test_frames)/self.chonk_len)\n",
    "\n",
    "\n",
    "        for index in range(len(test_frames[:slice_len])):\n",
    "            frame_counter += 1\n",
    "            new_frames.append(test_frames[index].flatten())\n",
    "            if frame_counter == self.chonk_len:\n",
    "                frame_counter = 0\n",
    "                blocks.append(np.array(new_frames))\n",
    "                new_labels = new_labels + [label]\n",
    "                new_frames = []\n",
    "\n",
    "        return blocks, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "cellId": "1k6x31a2z0ipunh91m1tsg"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "dataset = Skeleton_Dataset(data, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "cellId": "uryetmnbtdlb775awv5mrq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(586, 3376)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "dataset.data[:int(0.75*len(dataset.data))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "cellId": "jg8yxhudlxc41qvxi4n67s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "label = dataset.labels.values[41]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "cellId": "9rppob1gk9r3lwac6fadc2"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "skel, lab = dataset.__getitem__(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "cellId": "gac1oz3y1rror5cvykncl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "cellId": "u4vufy7zyyf3qa4fb853vc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 75)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "skel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "cellId": "p2rcgnudvhm9spvaddeca5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'standing up (from sitting position)',\n",
       " 1: 'reading',\n",
       " 2: 'hand waving',\n",
       " 3: 'kicking something',\n",
       " 4: 'make a phone call/answer phone',\n",
       " 5: 'cheer up'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "action_classes = [\n",
    "    \"drink water\",\n",
    "    \"eat meal/snack\",\n",
    "    \"brushing teeth\",\n",
    "    \"brushing hair\",\n",
    "    \"drop\",\n",
    "    \"pickup\",\n",
    "    \"throw\",\n",
    "    \"sitting down\",\n",
    "    \"standing up (from sitting position)\",\n",
    "    \"clapping\",\n",
    "    \"reading\",\n",
    "    \"writing\",\n",
    "    \"tear up paper\",\n",
    "    \"wear jacket\",\n",
    "    \"take off jacket\",\n",
    "    \"wear a shoe\",\n",
    "    \"take off a shoe\",\n",
    "    \"wear on glasses\",\n",
    "    \"take off glasses\",\n",
    "    \"put on a hat/cap\",\n",
    "    \"take off a hat/cap\",\n",
    "    \"cheer up\",\n",
    "    \"hand waving\",\n",
    "    \"kicking something\",\n",
    "    \"reach into pocket\",\n",
    "    \"hopping (one foot jumping)\",\n",
    "    \"jump up\",\n",
    "    \"make a phone call/answer phone\",\n",
    "    \"playing with phone/tablet\",\n",
    "    \"typing on a keyboard\",\n",
    "    \"pointing to something with finger\",\n",
    "    \"taking a selfie\",\n",
    "    \"check time (from watch)\",\n",
    "    \"rub two hands together\",\n",
    "    \"nod head/bow\",\n",
    "    \"shake head\",\n",
    "    \"wipe face\",\n",
    "    \"salute\",\n",
    "    \"put the palms together\",\n",
    "    \"cross hands in front (say stop)\",\n",
    "    \"sneeze/cough\",\n",
    "    \"staggering\",\n",
    "    \"falling\",\n",
    "    \"touch head (headache)\",\n",
    "    \"touch chest (stomachache/heart pain)\",\n",
    "    \"touch back (backache)\",\n",
    "    \"touch neck (neckache)\",\n",
    "    \"nausea or vomiting condition\",\n",
    "    \"use a fan (with hand or paper)/feeling warm\",\n",
    "    \"punching/slapping other person\",\n",
    "    \"kicking other person\",\n",
    "    \"pushing other person\",\n",
    "    \"pat on back of other person\",\n",
    "    \"point finger at the other person\",\n",
    "    \"hugging other person\",\n",
    "    \"giving something to other person\",\n",
    "    \"touch other person's pocket\",\n",
    "    \"handshaking\",\n",
    "    \"walking towards each other\",\n",
    "    \"walking apart from each other\",\n",
    "    \"put on headphone\",\n",
    "    \"take off headphone\",\n",
    "    \"shoot at the basket\",\n",
    "    \"bounce ball\",\n",
    "    \"tennis bat swing\",\n",
    "    \"juggling table tennis balls\",\n",
    "    \"hush (quite)\",\n",
    "    \"flick hair\",\n",
    "    \"thumb up\",\n",
    "    \"thumb down\",\n",
    "    \"make ok sign\",\n",
    "    \"make victory sign\",\n",
    "    \"staple book\",\n",
    "    \"counting money\",\n",
    "    \"cutting nails\",\n",
    "    \"cutting paper (using scissors)\",\n",
    "    \"snapping fingers\",\n",
    "    \"open bottle\",\n",
    "    \"sniff (smell)\",\n",
    "    \"squat down\",\n",
    "    \"toss a coin\",\n",
    "    \"fold paper\",\n",
    "    \"ball up paper\",\n",
    "    \"play magic cube\",\n",
    "    \"apply cream on face\",\n",
    "    \"apply cream on hand back\",\n",
    "    \"put on bag\",\n",
    "    \"take off bag\",\n",
    "    \"put something into a bag\",\n",
    "    \"take something out of a bag\",\n",
    "    \"open a box\",\n",
    "    \"move heavy objects\",\n",
    "    \"shake fist\",\n",
    "    \"throw up cap/hat\",\n",
    "    \"hands up (both hands)\",\n",
    "    \"cross arms\",\n",
    "    \"arm circles\",\n",
    "    \"arm swings\",\n",
    "    \"running on the spot\",\n",
    "    \"butt kicks (kick backward)\",\n",
    "    \"cross toe touch\",\n",
    "    \"side kick\",\n",
    "    \"yawn\",\n",
    "    \"stretch oneself\",\n",
    "    \"blow nose\",\n",
    "    \"hit other person with something\",\n",
    "    \"wield knife towards other person\",\n",
    "    \"knock over other person (hit with body)\",\n",
    "    \"grab other person’s stuff\",\n",
    "    \"shoot at other person with a gun\",\n",
    "    \"step on foot\",\n",
    "    \"high-five\",\n",
    "    \"cheers and drink\",\n",
    "    \"carry something with other person\",\n",
    "    \"take a photo of other person\",\n",
    "    \"follow other person\",\n",
    "    \"whisper in other person’s ear\",\n",
    "    \"exchange things with other person\",\n",
    "    \"support somebody with hand\",\n",
    "    \"finger-guessing game (playing rock-paper-scissors)\"\n",
    "]\n",
    "LABELS = {0: \"cheer up\", 1: \"jump up\", 2:  \"hand waving\", 3: \"sitting down\", 4: \"clapping\"}\n",
    "classes = [8, 10, 22, 23, 27, 21]    \n",
    "LABELS = {i: action_classes[classes[i]] for i in range(6)}\n",
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "cellId": "vxpne3m3e4qptvfnx2t8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hand waving'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "LABELS[lab]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "o0chk4pkzdr9xcsp2u56b"
   },
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "fv2l0gnrpor0g2aqdv0uosf"
   },
   "source": [
    "Построить график зависимости от количества кадров в последовательности (уменьшать и увеличивать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "cellId": "gbkndxkpuss1jpbq8of9p1"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "class LSTM_net(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,output_dim,layer_num):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.lstm = torch.nn.LSTM(input_dim, hidden_dim,layer_num,batch_first=True)\n",
    "        self.dr = torch.nn.Dropout2d(0.1)\n",
    "        self.fc = torch.nn.Linear(hidden_dim,output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x = inputs\n",
    "        lstm_out,(hn,cn) = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:,-1,:])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "cellId": "dx6uvaif0np0xrp22vft89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "cellId": "a0naavvtm1oq85m5ec5di7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_net(\n",
       "  (lstm): LSTM(75, 128, num_layers=2, batch_first=True)\n",
       "  (dr): Dropout2d(p=0.1, inplace=False)\n",
       "  (fc): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "n_hidden = 128\n",
    "n_joints = 25*3\n",
    "n_categories = len(LABELS)\n",
    "n_layer = 2\n",
    "rnn = LSTM_net(n_joints,n_hidden,n_categories,n_layer)\n",
    "rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "cellId": "03qfp68mm3om0gho5z7mgkfh"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "#     print(output.topk(5))\n",
    "    return LABELS[category_i], category_i\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "cellId": "qpgzucqc6iswhaffq9cbbm"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "split_train_part = 0.75\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, \n",
    "                                                            [int(split_train_part*dataset.data.shape[0]), \n",
    "                                                             dataset.data.shape[0] - int(split_train_part*dataset.data.shape[0])])\n",
    "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "cellId": "t8nw8lsw1bkljjv9ksnqpc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 iter : 0 (0m 0s) 1.7793  / standing up (from sitting position) ✗ (reading)\n",
      "epoch : 13 iter : 19 (0m 20s) 1.7650  / hand waving ✗ (make a phone call/answer phone)\n",
      "epoch : 27 iter : 1 (0m 41s) 1.5809  / standing up (from sitting position) ✗ (make a phone call/answer phone)\n",
      "epoch : 40 iter : 20 (1m 1s) 1.7983  / reading ✗ (make a phone call/answer phone)\n",
      "epoch : 54 iter : 2 (1m 22s) 1.3202  / reading ✓\n",
      "epoch : 67 iter : 21 (1m 42s) 1.2090  / standing up (from sitting position) ✓\n",
      "epoch : 81 iter : 3 (2m 3s) 0.9431  / kicking something ✓\n",
      "epoch : 94 iter : 22 (2m 24s) 0.9488  / make a phone call/answer phone ✗ (cheer up)\n",
      "epoch : 108 iter : 4 (2m 44s) 1.0420  / reading ✗ (cheer up)\n",
      "epoch : 121 iter : 23 (3m 4s) 1.3536  / make a phone call/answer phone ✓\n",
      "epoch : 135 iter : 5 (3m 25s) 0.6645  / reading ✓\n",
      "epoch : 148 iter : 24 (3m 46s) 1.1627  / make a phone call/answer phone ✗ (reading)\n",
      "epoch : 162 iter : 6 (4m 6s) 0.4204  / cheer up ✗ (reading)\n",
      "epoch : 175 iter : 25 (4m 27s) 0.6787  / hand waving ✗ (reading)\n",
      "epoch : 189 iter : 7 (4m 47s) 0.7665  / standing up (from sitting position) ✓\n"
     ]
    }
   ],
   "source": [
    "#!L\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0007\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "all_losses = []\n",
    "start = time.time()\n",
    "counter = 0\n",
    "for epoch in range(200):  \n",
    "    current_loss = 0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        output = rnn(inputs.float())\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "\n",
    "        current_loss += loss.item()\n",
    "        category = LABELS[int(labels[0])]\n",
    "\n",
    "        if counter % 500 == 0:\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "            print('epoch : %d iter : %d (%s) %.4f  / %s %s' % (epoch, i, timeSince(start), loss, guess, correct))\n",
    "\n",
    "        \n",
    "        counter = counter + 1\n",
    "    if counter % 100 == 0:\n",
    "        all_losses.append(current_loss / 25)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "cellId": "w3hjoiqm839gws2fzxnt3a"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "data_path = \"nturgb+d_skeletons/\"\n",
    "broken_files_path = \"NTU_RGBD_samples_with_missing_skeletons.txt\"\n",
    "\n",
    "data = Croped_Raw_Data(data_path, broken_files_path)\n",
    "dataset_c35 = Skeleton_Dataset(data, data_path, chonk_len=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "cellId": "p81f09t0ts9ri1np0s385"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(905, 2626)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "dataset_c35.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "cellId": "ix92ward85f5jemp40ame9"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "skel, lab = dataset_c35.__getitem__(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "cellId": "bb9m7ielwjiufz44w4395k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 75)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "skel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "cellId": "2mti7yqd61mp5t4onr3muf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "cellId": "94ca7as24zkzw7k8q805h"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "split_train_part = 0.75\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset_c35, \n",
    "                                                            [int(split_train_part*dataset_c35.data.shape[0]), \n",
    "                                                             dataset_c35.data.shape[0] - int(split_train_part*dataset_c35.data.shape[0])])\n",
    "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "cellId": "gtro87hgkvh5rkpmjj43pr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_net(\n",
       "  (lstm): LSTM(75, 128, num_layers=2, batch_first=True)\n",
       "  (dr): Dropout2d(p=0.1, inplace=False)\n",
       "  (fc): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "n_hidden = 128\n",
    "n_joints = 25*3\n",
    "n_categories = len(LABELS)\n",
    "n_layer = 2\n",
    "rnn = LSTM_net(n_joints,n_hidden,n_categories,n_layer)\n",
    "rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "cellId": "gtziqrl7qtfa6k28ke17u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 iter : 0 (0m 0s) 1.8289  / standing up (from sitting position) ✓\n",
      "epoch : 11 iter : 27 (0m 17s) 1.7605  / hand waving ✗ (cheer up)\n",
      "epoch : 23 iter : 11 (0m 34s) 1.5320  / hand waving ✗ (cheer up)\n",
      "epoch : 34 iter : 38 (0m 51s) 1.4354  / standing up (from sitting position) ✗ (cheer up)\n",
      "epoch : 46 iter : 22 (1m 8s) 1.6923  / hand waving ✗ (cheer up)\n",
      "epoch : 58 iter : 6 (1m 25s) 1.2300  / hand waving ✗ (kicking something)\n",
      "epoch : 69 iter : 33 (1m 42s) 1.1184  / kicking something ✓\n",
      "epoch : 81 iter : 17 (1m 59s) 1.0343  / hand waving ✗ (kicking something)\n",
      "epoch : 93 iter : 1 (2m 16s) 1.1912  / kicking something ✗ (hand waving)\n",
      "epoch : 104 iter : 28 (2m 33s) 0.8668  / reading ✓\n",
      "epoch : 116 iter : 12 (2m 50s) 0.7947  / kicking something ✗ (hand waving)\n",
      "epoch : 127 iter : 39 (3m 7s) 1.0142  / hand waving ✗ (make a phone call/answer phone)\n",
      "epoch : 139 iter : 23 (3m 24s) 1.1213  / reading ✗ (standing up (from sitting position))\n",
      "epoch : 151 iter : 7 (3m 41s) 0.8545  / make a phone call/answer phone ✓\n",
      "epoch : 162 iter : 34 (3m 58s) 0.8356  / kicking something ✓\n",
      "epoch : 174 iter : 18 (4m 15s) 0.7865  / make a phone call/answer phone ✗ (reading)\n",
      "epoch : 186 iter : 2 (4m 32s) 0.9309  / reading ✓\n",
      "epoch : 197 iter : 29 (4m 49s) 0.8900  / standing up (from sitting position) ✓\n"
     ]
    }
   ],
   "source": [
    "#!L\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0007\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "all_losses = []\n",
    "start = time.time()\n",
    "counter = 0\n",
    "for epoch in range(200):  \n",
    "    current_loss = 0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        output = rnn(inputs.float())\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "\n",
    "        current_loss += loss.item()\n",
    "        category = LABELS[int(labels[0])]\n",
    "\n",
    "        if counter % 500 == 0:\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "            print('epoch : %d iter : %d (%s) %.4f  / %s %s' % (epoch, i, timeSince(start), loss, guess, correct))\n",
    "\n",
    "        \n",
    "        counter = counter + 1\n",
    "    if counter % 100 == 0:\n",
    "        all_losses.append(current_loss / 25)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "dzcrid5myn7zmslve4uns"
   },
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "4kh3lvhik2tte6286eyb38"
   },
   "source": [
    "Построить график зависимости от количества модулей LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "wqm8yrv0slcp23xromnvt"
   },
   "outputs": [],
   "source": [
    "#!L\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "notebookId": "c2b53adc-5e66-4c3c-a38c-4911243da2c5"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
